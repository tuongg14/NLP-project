{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1016fe2",
   "metadata": {},
   "source": [
    "### 1. Fix đường dẫn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9524488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: d:\\NLP\\NLP-project\n",
      "SRC_DIR added: d:\\NLP\\NLP-project\\src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent      # notebooks/ -> project/\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "\n",
    "sys.path.append(str(SRC_DIR))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"SRC_DIR added:\", SRC_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44f9b00",
   "metadata": {},
   "source": [
    "### 2. Import thư viện và module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217ef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    }
   ],
   "source": [
    "import time     # Đo thời gian huấn luyện và đánh giá\n",
    "import json     # Lưu kết quả (loss, BLEU, ...) ra file JSON\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader                     # Tạo batch dữ liệu\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau      # Giảm learning rate khi loss không cải thiện\n",
    "from tqdm import tqdm                                       # Hiển thị progress bar\n",
    "import sacrebleu                                            # Thư viện tính BLEU score\n",
    "\n",
    "from config_loader import load_config\n",
    "from data import (\n",
    "    read_lines, tokenize_en, tokenize_fr,       # Đọc và tokenize dữ liệu\n",
    "    build_vocab_from_token_lists,               # Xây dựng từ điển\n",
    "    TranslationDataset, build_collate_fn,       # Dataset và hàm gộp batch\n",
    "    PAD_TOKEN, SOS_TOKEN, EOS_TOKEN,            # Các token đặc biệt\n",
    ")\n",
    "from model import Encoder, Seq2SeqWithAttention, AttentionDecoder   # Các mô hình encoder-decoder\n",
    "\n",
    "# Chọn thiết bị tính toán: GPU nếu có, ngược lại dùng CPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6068dc08",
   "metadata": {},
   "source": [
    "### 3. Training & validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e06ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model, dataloader, optimizer, criterion,\n",
    "    teacher_forcing_ratio=0.5, clip=1.0, device=\"cpu\"\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for src, src_lens, tgt_in, tgt_out in tqdm(dataloader, desc=\"train\"):\n",
    "        # Đưa dữ liệu lên device (CPU/GPU)\n",
    "        src, src_lens = src.to(device), src_lens.to(device)\n",
    "        tgt_in, tgt_out = tgt_in.to(device), tgt_out.to(device)\n",
    "\n",
    "        optimizer.zero_grad()   # Reset gradient\n",
    "\n",
    "        # Forward pass với teacher forcing\n",
    "        output = model(\n",
    "            src, src_lens, tgt_in,\n",
    "            teacher_forcing_ratio=teacher_forcing_ratio\n",
    "        )\n",
    "        vocab_size = output.size(-1)\n",
    "\n",
    "        # Bỏ token <SOS> để căn chỉnh output và target\n",
    "        output = output[:, 1:, :].contiguous()\n",
    "        tgt_out = tgt_out[:, 1:].contiguous()\n",
    "\n",
    "        # Tính loss trên toàn bộ chuỗi\n",
    "        loss = criterion(\n",
    "            output.view(-1, vocab_size),\n",
    "            tgt_out.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        # Giới hạn gradient để tránh exploding gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()    # Cập nhật trọng số\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate_epoch(model, dataloader, criterion, device=\"cpu\"):\n",
    "    model.eval()    # Chuyển sang chế độ đánh giá\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():   # Không tính gradient khi validation\n",
    "        for src, src_lens, tgt_in, tgt_out in tqdm(dataloader, desc=\"val\"):\n",
    "            src, src_lens = src.to(device), src_lens.to(device)\n",
    "            tgt_in, tgt_out = tgt_in.to(device), tgt_out.to(device)\n",
    "\n",
    "            # Không dùng teacher forcing khi đánh giá\n",
    "            output = model(src, src_lens, tgt_in, teacher_forcing_ratio=0.0)\n",
    "            vocab_size = output.size(-1)\n",
    "\n",
    "            output = output[:, 1:, :].contiguous()\n",
    "            tgt_out = tgt_out[:, 1:].contiguous()\n",
    "\n",
    "            loss = criterion(\n",
    "                output.view(-1, vocab_size),\n",
    "                tgt_out.view(-1)\n",
    "            )\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1cde2",
   "metadata": {},
   "source": [
    "### 4. BLEU evaluation helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4de93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_tok_from_idx(vocab, idx: int):\n",
    "    # Trả về token tương ứng với index, tránh lỗi out-of-range\n",
    "    try:\n",
    "        if 0 <= idx < len(vocab.itos):\n",
    "            return vocab.itos[idx]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"<unk>\"  # Token không xác định\n",
    "\n",
    "def generate_hyps_from_loader(model, dataloader, tgt_vocab, max_len=50, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    hyps, refs = [], []\n",
    "\n",
    "    with torch.no_grad():   # Không tính gradient khi generate\n",
    "        for src, src_lens, tgt_in, tgt_out in tqdm(dataloader, desc=\"generate\"):\n",
    "            src, src_lens = src.to(device), src_lens.to(device)\n",
    "\n",
    "            # Greedy decoding: sinh từng token một cho đến <EOS> hoặc max_len\n",
    "            preds = model.greedy_decode(\n",
    "                src, src_lens,\n",
    "                max_len=max_len,\n",
    "                sos_idx=tgt_vocab.stoi[SOS_TOKEN],\n",
    "                eos_idx=tgt_vocab.stoi[EOS_TOKEN],\n",
    "            )\n",
    "            \n",
    "            # Chuyển output dự đoán từ index → câu\n",
    "            for seq in preds:\n",
    "                tokens = []\n",
    "                for idx in seq:\n",
    "                    if idx == tgt_vocab.stoi[EOS_TOKEN]:\n",
    "                        break\n",
    "                    tok = safe_tok_from_idx(tgt_vocab, int(idx))\n",
    "                    if tok not in (PAD_TOKEN, SOS_TOKEN, EOS_TOKEN):\n",
    "                        tokens.append(tok)\n",
    "                hyps.append(\" \".join(tokens))\n",
    "\n",
    "            # Chuyển câu tham chiếu (ground truth) từ index → câu\n",
    "            tgt_np = tgt_out.cpu().numpy()\n",
    "            for line in tgt_np:\n",
    "                tokens = []\n",
    "                for idx in line:\n",
    "                    if idx == tgt_vocab.stoi[EOS_TOKEN]:\n",
    "                        break\n",
    "                    tok = safe_tok_from_idx(tgt_vocab, int(idx))\n",
    "                    if tok not in (PAD_TOKEN, SOS_TOKEN, EOS_TOKEN):\n",
    "                        tokens.append(tok)\n",
    "                refs.append(\" \".join(tokens))\n",
    "\n",
    "    return hyps, refs\n",
    "\n",
    "def compute_corpus_bleu(hyps, refs):\n",
    "    # Tính BLEU score ở mức corpus bằng sacreBLEU\n",
    "    bleu = sacrebleu.corpus_bleu(hyps, [refs], force=True)\n",
    "    return bleu.score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e6e7c5",
   "metadata": {},
   "source": [
    "### 5. Load config & hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "device = DEVICE\n",
    "\n",
    "train_cfg = config[\"training\"]  # Nhóm tham số huấn luyện\n",
    "BATCH_SIZE = train_cfg[\"batch_size\"]\n",
    "NUM_EPOCHS = train_cfg[\"num_epochs\"]\n",
    "LEARNING_RATE = train_cfg[\"learning_rate\"]\n",
    "\n",
    "# Teacher Forcing: cấu hình giá trị ban đầu + giảm dần theo epoch\n",
    "BASE_TF = train_cfg[\"teacher_forcing\"]\n",
    "MIN_TF = train_cfg.get(\"min_teacher_forcing\", 0.1)\n",
    "TF_DECAY = train_cfg.get(\"tf_decay\", 0.97)\n",
    "\n",
    "CLIP = train_cfg[\"clip\"]\n",
    "MAX_LEN = train_cfg.get(\"max_len\", 50)  # Độ dài tối đa khi inference/decoding\n",
    "\n",
    "# Early stopping: dừng sớm nếu validation không cải thiện đủ trong 3 epoch liên tiếp\n",
    "EARLY_PATIENCE = train_cfg.get(\"early_patience\", 3)\n",
    "EARLY_MIN_DELTA = train_cfg.get(\"early_min_delta\", 1e-4)\n",
    "\n",
    "model_cfg = config[\"model\"] # Nhóm tham số kiến trúc mô hình\n",
    "EMB_DIM = model_cfg[\"emb_dim\"]\n",
    "HID_DIM = model_cfg[\"hid_dim\"]\n",
    "N_LAYERS = model_cfg[\"n_layers\"]\n",
    "DROPOUT = model_cfg[\"dropout\"]\n",
    "\n",
    "data_cfg = config[\"data\"]\n",
    "data_dir = PROJECT_ROOT / data_cfg[\"data_dir\"]\n",
    "\n",
    "paths_cfg = config[\"paths\"]\n",
    "ckpt_path = PROJECT_ROOT / paths_cfg[\"checkpoint\"]  # Đường dẫn lưu checkpoint model\n",
    "ckpt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "results_dir = PROJECT_ROOT / paths_cfg.get(\"results\", \"results\")    # Thư mục lưu kết quả/biểu đồ\n",
    "results_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc93db37",
   "metadata": {},
   "source": [
    "### 6. Load data & build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655fe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "SRC vocab: 5893\n",
      "TGT vocab: 6470\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "\n",
    "# Đọc dữ liệu song ngữ từ các file train/val\n",
    "train_src = read_lines(data_dir / \"train.en\")\n",
    "train_tgt = read_lines(data_dir / \"train.fr\")\n",
    "val_src = read_lines(data_dir / \"val.en\")\n",
    "val_tgt = read_lines(data_dir / \"val.fr\")\n",
    "\n",
    "# Tokenize câu nguồn (EN) và câu đích (FR)\n",
    "train_src_tok = [tokenize_en(s) for s in train_src]\n",
    "train_tgt_tok = [tokenize_fr(s) for s in train_tgt]\n",
    "val_src_tok = [tokenize_en(s) for s in val_src]\n",
    "val_tgt_tok = [tokenize_fr(s) for s in val_tgt]\n",
    "\n",
    "MIN_FREQ = config[\"vocab\"][\"min_freq\"]  # Ngưỡng tần suất tối thiểu để đưa token vào vocab\n",
    "\n",
    "# Xây dựng từ điển chỉ dựa trên tập train để tránh data leakage\n",
    "src_vocab = build_vocab_from_token_lists(train_src_tok, min_freq=MIN_FREQ)\n",
    "tgt_vocab = build_vocab_from_token_lists(train_tgt_tok, min_freq=MIN_FREQ)\n",
    "\n",
    "print(\"SRC vocab:\", len(src_vocab))\n",
    "print(\"TGT vocab:\", len(tgt_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b727d6",
   "metadata": {},
   "source": [
    "### 7. Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a0821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo dataset cho tập train và validation\n",
    "train_ds = TranslationDataset(train_src_tok, train_tgt_tok, src_vocab, tgt_vocab)\n",
    "val_ds = TranslationDataset(val_src_tok, val_tgt_tok, src_vocab, tgt_vocab)\n",
    "\n",
    "# Collate function: padding chuỗi, tạo tensor và độ dài câu cho encoder\n",
    "collate_fn = build_collate_fn(src_vocab, tgt_vocab)\n",
    "\n",
    "# DataLoader cho huấn luyện (shuffle để tăng tính ngẫu nhiên)\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE,\n",
    "    shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# DataLoader cho validation (không shuffle)\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE,\n",
    "    shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fd582f",
   "metadata": {},
   "source": [
    "### 8. Init model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: bỏ qua padding khi tính Cross-Entropy\n",
    "pad_idx = tgt_vocab.stoi[PAD_TOKEN]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "# Khởi tạo Encoder (LSTM)\n",
    "enc = Encoder(\n",
    "    len(src_vocab),\n",
    "    EMB_DIM,\n",
    "    HID_DIM,\n",
    "    N_LAYERS,\n",
    "    DROPOUT,\n",
    "    pad_idx=src_vocab.stoi.get(PAD_TOKEN, 0)\n",
    ")\n",
    "\n",
    "# Khởi tạo Decoder có Attention\n",
    "dec = AttentionDecoder(\n",
    "    len(tgt_vocab),\n",
    "    EMB_DIM,\n",
    "    HID_DIM,\n",
    "    N_LAYERS,\n",
    "    DROPOUT\n",
    ")\n",
    "\n",
    "# Mô hình Seq2Seq kết hợp Encoder + Decoder + Attention\n",
    "model = Seq2SeqWithAttention(enc, dec, device).to(device)\n",
    "\n",
    "# Optimizer Adam cho toàn bộ tham số mô hình\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Scheduler: giảm learning rate khi validation loss không cải thiện\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c9fde6",
   "metadata": {},
   "source": [
    "### 9. Training loop (core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022fbbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "=== Epoch 1/12 | TF=0.500 | LR=0.000700 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 454/454 [21:07<00:00,  2.79s/it]  \n",
      "val: 100%|██████████| 16/16 [00:14<00:00,  1.13it/s]\n",
      "generate: 100%|██████████| 16/16 [00:11<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.983 | Val Loss: 4.387 | Gap: 0.596 | Val BLEU: 2.75 | Time: 1294.5s\n",
      "Saved best checkpoint (by Val BLEU)\n",
      "\n",
      "=== Epoch 2/12 | TF=0.485 | LR=0.000700 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 454/454 [19:47<00:00,  2.62s/it]\n",
      "val: 100%|██████████| 16/16 [00:07<00:00,  2.09it/s]\n",
      "generate: 100%|██████████| 16/16 [00:07<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.041 | Val Loss: 3.846 | Gap: 0.195 | Val BLEU: 8.39 | Time: 1202.7s\n",
      "Saved best checkpoint (by Val BLEU)\n",
      "\n",
      "=== Epoch 3/12 | TF=0.470 | LR=0.000700 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 454/454 [17:53<00:00,  2.37s/it] \n",
      "val: 100%|██████████| 16/16 [00:07<00:00,  2.02it/s]\n",
      "generate: 100%|██████████| 16/16 [00:08<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.560 | Val Loss: 3.563 | Gap: 0.003 | Val BLEU: 11.76 | Time: 1090.1s\n",
      "Saved best checkpoint (by Val BLEU)\n",
      "\n",
      "=== Epoch 4/12 | TF=0.456 | LR=0.000700 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 454/454 [15:57<00:00,  2.11s/it]\n",
      "val: 100%|██████████| 16/16 [00:08<00:00,  2.00it/s]\n",
      "generate: 100%|██████████| 16/16 [00:07<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.238 | Val Loss: 3.387 | Gap: 0.150 | Val BLEU: 14.71 | Time: 973.2s\n",
      "Saved best checkpoint (by Val BLEU)\n",
      "\n",
      "=== Epoch 5/12 | TF=0.443 | LR=0.000700 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 454/454 [18:08<00:00,  2.40s/it]\n",
      "val: 100%|██████████| 16/16 [00:11<00:00,  1.41it/s]\n",
      "generate: 100%|██████████| 16/16 [00:09<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.005 | Val Loss: 3.283 | Gap: 0.278 | Val BLEU: 16.40 | Time: 1109.8s\n",
      "Saved best checkpoint (by Val BLEU)\n",
      "\n",
      "=== Epoch 6/12 | TF=0.429 | LR=0.000700 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 454/454 [18:54<00:00,  2.50s/it]\n",
      "val: 100%|██████████| 16/16 [00:11<00:00,  1.45it/s]\n",
      "generate: 100%|██████████| 16/16 [00:10<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.814 | Val Loss: 3.131 | Gap: 0.316 | Val BLEU: 18.74 | Time: 1156.2s\n",
      "Saved best checkpoint (by Val BLEU)\n",
      "\n",
      "=== Epoch 7/12 | TF=0.416 | LR=0.000700 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 454/454 [20:01<00:00,  2.65s/it]\n",
      "val: 100%|██████████| 16/16 [00:07<00:00,  2.00it/s]\n",
      "generate: 100%|██████████| 16/16 [00:07<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.679 | Val Loss: 3.018 | Gap: 0.339 | Val BLEU: 20.37 | Time: 1217.9s\n",
      "Saved best checkpoint (by Val BLEU)\n",
      "\n",
      "=== Epoch 8/12 | TF=0.404 | LR=0.000700 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 454/454 [19:33<00:00,  2.59s/it]\n",
      "val: 100%|██████████| 16/16 [00:07<00:00,  2.01it/s]\n",
      "generate: 100%|██████████| 16/16 [00:07<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.553 | Val Loss: 2.973 | Gap: 0.420 | Val BLEU: 21.21 | Time: 1189.4s\n",
      "Saved best checkpoint (by Val BLEU)\n",
      "\n",
      "=== Epoch 9/12 | TF=0.392 | LR=0.000700 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 454/454 [16:24<00:00,  2.17s/it]\n",
      "val: 100%|██████████| 16/16 [00:08<00:00,  1.93it/s]\n",
      "generate: 100%|██████████| 16/16 [00:07<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.434 | Val Loss: 2.946 | Gap: 0.512 | Val BLEU: 22.37 | Time: 1000.8s\n",
      "Saved best checkpoint (by Val BLEU)\n",
      "\n",
      "=== Epoch 10/12 | TF=0.380 | LR=0.000700 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 454/454 [16:29<00:00,  2.18s/it]\n",
      "val: 100%|██████████| 16/16 [00:07<00:00,  2.04it/s]\n",
      "generate: 100%|██████████| 16/16 [00:07<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.329 | Val Loss: 2.905 | Gap: 0.576 | Val BLEU: 22.51 | Time: 1005.6s\n",
      "Saved best checkpoint (by Val BLEU)\n",
      "\n",
      "=== Epoch 11/12 | TF=0.369 | LR=0.000700 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 454/454 [16:17<00:00,  2.15s/it]\n",
      "val: 100%|██████████| 16/16 [00:08<00:00,  1.97it/s]\n",
      "generate: 100%|██████████| 16/16 [00:08<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.252 | Val Loss: 2.874 | Gap: 0.622 | Val BLEU: 24.13 | Time: 994.4s\n",
      "Saved best checkpoint (by Val BLEU)\n",
      "\n",
      "=== Epoch 12/12 | TF=0.358 | LR=0.000700 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 454/454 [20:43<00:00,  2.74s/it]\n",
      "val: 100%|██████████| 16/16 [00:08<00:00,  1.90it/s]\n",
      "generate: 100%|██████████| 16/16 [00:07<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.173 | Val Loss: 2.846 | Gap: 0.673 | Val BLEU: 24.47 | Time: 1259.7s\n",
      "Saved best checkpoint (by Val BLEU)\n"
     ]
    }
   ],
   "source": [
    "# Log lại loss và BLEU theo từng epoch\n",
    "train_loss_log, val_loss_log, val_bleu_log = [], [], []\n",
    "\n",
    "best_bleu = -1.0\n",
    "best_val_loss_report = float(\"inf\")\n",
    "\n",
    "best_val_loss_es = float(\"inf\")\n",
    "bad_epochs = 0\n",
    "\n",
    "print(\"Training model...\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Teacher forcing decay theo epoch\n",
    "    tf_ratio = max(\n",
    "        MIN_TF,\n",
    "        BASE_TF * (TF_DECAY ** (epoch - 1))\n",
    "    )\n",
    "\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    print(f\"\\n=== Epoch {epoch}/{NUM_EPOCHS} | TF={tf_ratio:.3f} | LR={lr:.6f} ===\")\n",
    "\n",
    "    train_loss = train_epoch(\n",
    "        model, train_loader, optimizer, criterion,\n",
    "        teacher_forcing_ratio=tf_ratio,\n",
    "        clip=CLIP,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Đánh giá trên validation set\n",
    "    val_loss = evaluate_epoch(model, val_loader, criterion, device=device)\n",
    "\n",
    "    # Sinh câu dịch và tính BLEU trên tập validation\n",
    "    hyps, refs = generate_hyps_from_loader(\n",
    "        model, val_loader, tgt_vocab,\n",
    "        max_len=MAX_LEN,\n",
    "        device=device,\n",
    "    )\n",
    "    val_bleu = compute_corpus_bleu(hyps, refs)\n",
    "\n",
    "    train_loss_log.append(train_loss)\n",
    "    val_loss_log.append(val_loss)\n",
    "    val_bleu_log.append(val_bleu)\n",
    "\n",
    "    # Cập nhật learning rate dựa trên validation loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    gap = abs(train_loss - val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Train Loss: {train_loss:.3f} | \"\n",
    "        f\"Val Loss: {val_loss:.3f} | \"\n",
    "        f\"Gap: {gap:.3f} | \"\n",
    "        f\"Val BLEU: {val_bleu:.2f} | \"\n",
    "        f\"Time: {elapsed:.1f}s\"\n",
    "    )\n",
    "\n",
    "    # Theo dõi loss tốt nhất để báo cáo\n",
    "    if val_loss < best_val_loss_report:\n",
    "        best_val_loss_report = val_loss\n",
    "\n",
    "    # Lưu checkpoint theo BLEU tốt nhất\n",
    "    if val_bleu > best_bleu:\n",
    "        best_bleu = val_bleu\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"src_itos\": src_vocab.itos,\n",
    "                \"tgt_itos\": tgt_vocab.itos,\n",
    "                \"config\": config,\n",
    "                \"epoch\": epoch,\n",
    "                \"val_bleu\": best_bleu,\n",
    "            },\n",
    "            ckpt_path,\n",
    "        )\n",
    "        print(\"Saved best checkpoint (by Val BLEU)\")\n",
    "\n",
    "    # Early stopping theo validation loss\n",
    "    if val_loss < best_val_loss_es - EARLY_MIN_DELTA:\n",
    "        best_val_loss_es = val_loss\n",
    "        bad_epochs = 0\n",
    "    else:\n",
    "        bad_epochs += 1\n",
    "\n",
    "    if bad_epochs >= EARLY_PATIENCE:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8e4435",
   "metadata": {},
   "source": [
    "### 10. Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be39efc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metrics to: d:\\NLP\\NLP-project\\results\\metrics.json\n",
      "\n",
      "Training finished.\n",
      "Best Val Loss = 2.846\n",
      "Best Val BLEU = 24.47\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    \"train_loss\": train_loss_log,\n",
    "    \"val_loss\": val_loss_log,\n",
    "    \"val_bleu\": val_bleu_log,\n",
    "}\n",
    "\n",
    "# Lưu metrics ra file JSON để phục vụ vẽ biểu đồ và báo cáo\n",
    "metrics_path = results_dir / \"metrics.json\"\n",
    "with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Saved metrics to:\", metrics_path)\n",
    "\n",
    "print(\n",
    "    f\"\\nTraining finished.\\n\"\n",
    "    f\"Best Val Loss = {best_val_loss_report:.3f}\\n\"\n",
    "    f\"Best Val BLEU = {best_bleu:.2f}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
